from llmedit.core.models.settings import ModelInformation

PREDEFINED_GGUF_MODELS = [
    ModelInformation(
        name='DeepSeek-R1-Distill-Llama-8B',
        repositoryId='unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF',
        fileName='DeepSeek-R1-Distill-Llama-8B-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.6,
        top_k=40,
        top_p=0.95,
        min_p=0.05,
        system_prompt_prefix='<｜System｜>',
        user_prompt_prefix='<｜User｜>',
        user_prompt_suffix='<｜Assistant｜>',
    ),
    ModelInformation(
        name='Qwen3-8B (Reasoning)',
        repositoryId='unsloth/Qwen3-8B-GGUF',
        fileName='Qwen3-8B-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.6,
        top_k=20,
        top_p=0.95,
        user_prompt_suffix='/think',
    ),
    ModelInformation(
        name='Qwen3-8B (Non-Reasoning)',
        repositoryId='unsloth/Qwen3-8B-GGUF',
        fileName='Qwen3-8B-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.7,
        top_k=20,
        top_p=0.8,
        user_prompt_suffix='/no_think',
    ),
    ModelInformation(
        name='Qwen3-14B (Reasoning)',
        repositoryId='unsloth/Qwen3-14B-GGUF',
        fileName='Qwen3-14B-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.6,
        top_k=20,
        top_p=0.95,
        user_prompt_suffix='/think',

    ),
    ModelInformation(
        name='Qwen3-14B (Non-Reasoning)',
        repositoryId='unsloth/Qwen3-14B-GGUF',
        fileName='Qwen3-14B-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.7,
        top_k=20,
        top_p=0.8,
        user_prompt_suffix='/no_think',
    ),
    ModelInformation(
        name='Qwen3-30B-A3B-Instruct-2507',
        repositoryId='unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF',
        fileName='Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.7,
        top_k=20,
        top_p=0.8,
    ),
    ModelInformation(
        name='gemma-3n-E4B-it',
        repositoryId='unsloth/gemma-3n-E4B-it-GGUF',
        fileName='gemma-3n-E4B-it-Q4_K_M.gguf',
        output_length=32768,
        temperature=1.0,
        top_k=64,
        top_p=0.95,
    ),
    ModelInformation(
        name='gemma-3-12b-it-qat',
        repositoryId='unsloth/gemma-3-12b-it-qat-GGUF',
        fileName='gemma-3-12b-it-qat-Q4_K_M.gguf',
        output_length=32768,
        temperature=1.0,
        top_k=64,
        top_p=0.95,
    ),
    ModelInformation(
        name='gemma-3-27b-it-qat',
        repositoryId='unsloth/gemma-3-27b-it-qat-GGUF',
        fileName='gemma-3-27b-it-qat-Q4_K_M.gguf',
        output_length=32768,
        temperature=1.0,
        top_k=64,
        top_p=0.95,
    ),
    ModelInformation(
        name='Mistral-Small-3.2-24B-Instruct-2506',
        repositoryId='unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF',
        fileName='Mistral-Small-3.2-24B-Instruct-2506-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.15,
        top_k=64,
        top_p=1.0,
    ),
    ModelInformation(
        name='Llama-3.1-8B-Instruct',
        repositoryId='unsloth/Llama-3.1-8B-Instruct-GGUF',
        fileName='Llama-3.1-8B-Instruct-Q4_K_M.gguf',
        output_length=32768,
        temperature=0.6,
        top_k=64,
        top_p=0.9,
    )
]
